#

version: '3'

volumes:
  import_done:
  import_queue:
  cache:

services:

  db:
    image: kartoza/postgis:13.0
    volumes:
      - ./postgis_data:/var/lib/postgresql
    environment:
      - POSTGRES_DB=gis
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASS=${POSTGRES_PASSWORD}
      - ALLOW_IP_RANGE=0.0.0.0/0
    networks:
     - qgis-server-net
    ports:
      - 15432:5432 
    restart: unless-stopped
    healthcheck:
        test: "exit 0"

  # This is a storage container for the country pbf
  pbf:
    image: pbf:stable
    build:
      context: ./pbf_fetcher
      dockerfile: Dockerfile

  imposm:
    image: kartoza/docker-osm:imposm-latest
    volumes:
      # These are sharable to other containers
      - ./osm_conf:/home/settings
      - import_done:/home/import_done
      - import_queue:/home/import_queue
      - cache:/home/cache
    depends_on:
      - db
    networks:
     - qgis-server-net
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASS=${POSTGRES_PASSWORD}
      - POSTGRES_DBNAME=gis
      - POSTGRES_PORT=5432
      - POSTGRES_HOST=db
      # seconds between 2 executions of the script
      # if 0, then no update will be done, only the first initial import from the PBF
      - TIME=120
      # folder for settings (with *.json and *.sql)
      - SETTINGS=settings
      # folder for caching
      - CACHE=cache
      # folder for diff which has been imported
      - IMPORT_DONE=import_done
      # folder for diff which hasn't been imported yet
      - IMPORT_QUEUE=import_queue
      # it can be 3857
      - SRID=4326
      # see http://imposm.org/docs/imposm3/latest/tutorial.html#optimize
      - OPTIMIZE=false
      # see http://imposm.org/docs/imposm3/latest/tutorial.html#deploy-production-tables
      - DBSCHEMA_PRODUCTION=public
      # http://imposm.org/docs/imposm3/latest/tutorial.html#deploy-production-tables
      - DBSCHEMA_IMPORT=import
      # http://imposm.org/docs/imposm3/latest/tutorial.html#deploy-production-tables
      - DBSCHEMA_BACKUP=backup
      # Install some styles if you are using the default mapping. It can be 'yes' or 'no'
      - QGIS_STYLE=yes
      # Use clip in the database
      - CLIP=yes

  osmupdate:
    image: kartoza/docker-osm:osmupdate-latest
    volumes:
      # These are sharable to other containers
      - ./osm_conf:/home/settings
      - import_done:/home/import_done
      - import_queue:/home/import_queue
      - cache:/home/cache
    depends_on:
      - db
    networks:
     - qgis-server-net
    environment:
      # These are all currently the defaults but listed here for your
      # convenience if you want to change them
      # the maximum time range to assemble a cumulated changefile.
      - MAX_DAYS=100
      # osmupdate uses a combination of minutely, hourly and daily changefiles. This value can be minute, hour, day or sporadic.
      - DIFF=sporadic
      # argument to determine the maximum number of parallely processed changefiles.
      - MAX_MERGE=7
      # define level for gzip compression. values between 1 (low compression but fast) and 9 (high compression but slow)
      - COMPRESSION_LEVEL=1
      # change the URL to use a custom URL to fetch regional file updates.
      - BASE_URL=http://planet.openstreetmap.org/replication/
      # folder for diff which hasn't been imported yet
      - IMPORT_QUEUE=import_queue
      # folder for diff which has been imported
      - IMPORT_DONE=import_done
      # seconds between 2 executions of the script
      # if 0, then no update will be done, only the first initial import from the PBF
      - TIME=120

  osmenrich:
    image: kartoza/docker-osm:osmenrich-latest
    volumes:
      # These are sharable to other containers
      - ./osm_conf:/home/settings
      - import_done:/home/import_done
      - import_queue:/home/import_queue
      - cache:/home/cache
    depends_on:
      - db
    networks:
     - qgis-server-net
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASS=${POSTGRES_PASSWORD}
      - POSTGRES_DBNAME=gis
      - POSTGRES_PORT=5432
      - POSTGRES_HOST=db
      # These are all currently the defaults but listed here for your
      #      # convenience if you want to change them
      #      # folder for diff which hasn't been imported yet
      #      - IMPORT_QUEUE=import_queue
      #      # folder for diff which has been imported
      #      - IMPORT_DONE=import_done
      #      # seconds between 2 executions of the script
      #      # if 0, then no update will be done, only the first initial import from the PBF
      #    command: bash -c "while [ ! -f /home/settings/importer.lock ] ; do sleep 1; done && python3 -u /home/enrich.py"
      #      - TIME=120

  geoserver:
    image: kartoza/geoserver:2.18.0
    volumes:
      # Must create this dir yourself so that it is owned by you
      - ./geoserver_data:/opt/geoserver/data_dir
    restart: on-failure
    environment:
      - GEOSERVER_ADMIN_PASSWORD=${GEOSERVER_ADMIN_PASSWORD}
      - GEOSERVER_ADMIN_USER=${GEOSERVER_ADMIN_USER}
      - INITIAL_MEMORY=${INITIAL_MEMORY}
      - MAXIMUM_MEMORY=${MAXIMUM_MEMORY}
    networks:
     - qgis-server-net
    depends_on:
      - db
    healthcheck:
      test: curl --fail -s http://localhost:8080/ || exit 1
      interval: 1m30s
      timeout: 10s
      retries: 3

  mergin-sync:
    image: "mergin_db_sync"
    volumes:
      # We do this so we can easily inspect what is being pulled down 
      # from merging, flush the working dir when needed etc
      - ./mergin_sync_data:/tmp
    environment:
      - DB_CONN_INFO=host=db dbname=gis user=${POSTGRES_USER} password=${POSTGRES_PASSWORD}
      - DB_SCHEMA_MODIFIED=${DB_SCHEMA_MODIFIED}
      - DB_SCHEMA_BASE=${DB_SCHEMA_BASE}
      - MERGIN_USERNAME=${MERGIN_USER}
      - MERGIN_PASSWORD=${MERGIN_PASSWORD}
      - MERGIN_PROJECT_NAME=${MERGIN_PROJECT_NAME}
      - MERGIN_SYNC_FILE=${MERGIN_SYNC_FILE}
    # Ultimately we want to swap to having the db as the master copy 
    # If you are using the geopackage as the master copy
    entrypoint: "python3 dbsync_daemon.py --init-from-gpkg"
    # If you are using the database as the master copy
    #entrypoint: "python3 dbsync_daemon.py --init-from-db"
    networks:
     - qgis-server-net
    restart: unless-stopped
    depends_on:
      - db 

  nginx:
    image: "nginx"
    volumes:
     - ./html:/var/www/html
     - ./nginx_conf/nginx.conf:/etc/nginx/nginx.conf
     - ./certbot/certbot/conf:/etc/letsencrypt
     - ./certbot/certbot/www:/var/www/certbot
    # This makes nginx reload its configuration (and certificates) every six hours in the background and launches nginx in the foreground.
    # See https://medium.com/@pentacent/nginx-and-lets-encrypt-with-docker-in-less-than-5-minutes-b4b8a60d3a71
    command: "/bin/sh -c 'while :; do sleep 6h & wait $${!}; nginx -s reload; done & nginx -g \"daemon off;\"'"
    ports:
     - "80:80"
     - "443:443"
    networks:
     - qgis-server-net
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: 200m
        max-file: '10'
    depends_on:
      - qgis-server
      - mapproxy
      - geoserver
      - postgrest
      - swagger

  certbot:
    image: certbot/certbot
    # This checks every 12 hours if our cert is up for renewal and refreshes it if needed
    # See https://medium.com/@pentacent/nginx-and-lets-encrypt-with-docker-in-less-than-5-minutes-b4b8a60d3a71
    entrypoint: "/bin/sh -c 'trap exit TERM; while :; do certbot renew; sleep 12h & wait $${!}; done;'"
    volumes:
     - ./certbot/certbot/conf:/etc/letsencrypt
     - ./certbot/certbot/www:/var/www/certbot

  qgis-server:
    image: "openquake/qgis-server:stable"
    #image: "openquake/qgis-server:3"
    environment:
      # Do not run the embedded copy of nginx
      SKIP_NGINX: "true"
      # Improve rendering performance
      QGIS_SERVER_PARALLEL_RENDERING: "true"
      QGIS_SERVER_MAX_THREADS: 4
      # Limit the maximum size returned by a GetMap
      QGIS_SERVER_WMS_MAX_HEIGHT: 5000
      QGIS_SERVER_WMS_MAX_WIDTH: 5000
      # Verbose logging
      QGIS_SERVER_LOG_LEVEL: 0
      # // Initialize the authentication system
      # // creates or uses qgis-auth.db in ~/.qgis3/ or directory defined by QGIS_AUTH_DB_DIR_PATH env variable
      # // set the master password as first line of file defined by QGIS_AUTH_PASSWORD_FILE env variable
      # // (QGIS_AUTH_PASSWORD_FILE variable removed from environment after accessing)
      # See also volume mounts below
      QGIS_AUTH_DB_DIR_PATH: /tmp/
      QGIS_AUTH_PASSWORD_FILE: /tmp/qgis-auth-pwd.txt
      # For OGC API
      # # Landing page plugin projects directory
      #QGIS_SERVER_LANDING_PAGE_PROJECTS_DIRECTORIES ${QGIS_SERVER_LANDING_PAGE_PROJECTS_DIRECTORIES}
      #QGIS_SERVER_LANDING_PAGE_PROJECTS_PG_CONNECTIONS postgresql://${POSTGRES_USER}:${POSTGRES_PASS}@postgis:5432?sslmode=disable&dbname=${POSTGRES_DBNAME}&schema=public`
    ports:
      - "9993"
    networks:
     - qgis-server-net
    volumes:
     # Data should be mount RO when working
     # with GeoPackages and more than one QGIS container
     # Data dir structure
     # $(pwd)/qgis_projects must have the following structure:
     # data
     # |
     # |-- <project_name>
     #   |-- <project_name>.qgs
     - ./qgis_projects:/io/data:ro
     # 
     # qgis_plugins
     # |
     # |-- <plugin_name>
     # |-- <plugin_code>.py
     # |-- metadata.txt
     # |-- __init__.py
     - ./qgis_plugins:/io/plugins
     # Custom fonts are loaded into /usr/share/fonts. fc-cache is run when container is started.
     - ./fonts:/usr/share/fonts
     - ./svg:/var/lib/qgis/.local/share/QGIS/QGIS3/profiles/default/svg
     - ./qgis_conf/qgis-auth.db:/tmp/qgis-auth.db
     - ./qgis_conf/qgis-auth-pwd.txt:/tmp/qgis-auth-pwd.txt
     # Working path for the pg_service file if using openquake/qgis-server:stable
     # See https://github.com/gem/oq-qgis-server/issues/54
     # The service file contains two service definitions
     # nginx - used for connecting to the database to load a QGIS project stored in the database
     #         In that case you cannot yet use qgis-auth.db database for user/pass credentials
     # smallholding - used for layer definitions. This service has no user/pass data and 
     #         instead we fetch those credentials from the qgis authdb
     - ./pg_conf/pg_service.conf:/etc/postgresql-common/pg_service.conf:ro
     # As per the oq QGIS Server docs at https://github.com/gem/oq-qgis-server/blob/master/README.md#postgresql-connection-service-file-optional but wrong! 
     #This works instead for the openquake/qgis-server:3 image
     #- ./pg_conf/pg_service.conf:/etc/pg_service.conf:ro
    depends_on:
      - db
    restart: unless-stopped

  mapproxy:
    image: kartoza/mapproxy
    environment:
      - PRODUCTION=false
      - PROCESSES=4
      - THREADS=10
    user: "1000:10001"
    volumes:
      - ./mapproxy_conf:/mapproxy
    depends_on:
      - qgis-server
    networks:
     - qgis-server-net

  postgrest:
    #
    # Used for pushing readings from IoT devices to our database
    #
    image: postgrest/postgrest
    environment:
      PGRST_DB_URI: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/gis
      PGRST_DB_SCHEMA: ${PGRST_DB_SCHEMA}
      # In production this role should not be the same as the one used for the connection
      # depends_on
      PGRST_DB_ANON_ROLE: ${PGRST_DB_ANON_ROLE}
      PGRST_SERVER_PROXY_URI: ${PGRST_SERVER_PROXY_URI}
      PGRST_OPENAPI_SERVER_PROXY_URI: ${PGRST_OPENAPI_SERVER_PROXY_URI}
      PGRST_SERVER_PORT: ${PGRST_SERVER_PORT}
    links:
      - db:db
    ports:
      - "3000"
    depends_on:
      - db
    networks:
      - qgis-server-net

  swagger:
    image: swaggerapi/swagger-ui
    ports:
      - "3001:8080"
    volumes:
      - ./swagger_conf/swagger.json:/swagger.json
    environment:
      SWAGGER_JSON: /swagger.json
      API_URL: ${API_URL}       
    depends_on:
      - db
      - postgrest
    networks:
      - qgis-server-net

networks:
  qgis-server-net:
